% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/generic_gof_tests.R
\name{gof_test_sim}
\alias{gof_test_sim}
\title{Perform a goodness of fit test using simulation}
\usage{
gof_test_sim(
  x,
  test_type = c("KS", "AD"),
  dist = "norm",
  noverlap = 1,
  fn_estimate_params = estimate_MoM_2,
  nreps = 999,
  parallelise = FALSE,
  ncores = NULL,
  bs_ci = NULL,
  nreps_bs_ci = 10000
)
}
\arguments{
\item{x}{The data being tested.}

\item{test_type}{The type of the test. Either a character string (KS and AD are supported)
or a function that implements a different test statistic with the same signature as
\code{\link{calc_ks_test_stat}} or \code{\link{calc_ad_test_stat}}.}

\item{dist}{The name of a distribution, such that it can be prepended by \code{"p"} to get
a probability function, and by \code{"r"} to get a random simulation function.
For example \code{"norm"} or \code{"unif"}.}

\item{noverlap}{The extent of any overlap in the data. \code{1} means no overlap,
and the test operates by ordinary simulation. If \code{noverlap > 1} then
autocorrelation will be induced in the simulations that is consistent with the degree of overlap,
to give unbiased test results. \code{fn_estimate_params} must also allow for the degree of overlap.}

\item{fn_estimate_params}{A function that takes the data and returns an object representing
the parameters of the distribution being fitted.}

\item{nreps}{The number of repetitions of the simulation to use.}

\item{parallelise}{Flag indicating whether or not to parallelise the calculations.}

\item{ncores}{The number of cores to use when parallelising.
\code{NULL} means one fewer than the number of cores on the machine.}

\item{bs_ci}{The width of a confidence interval around the p value,
which will be calculated using a non-parametric bootstrap.
\code{NULL} means no confidence interval will be produced.}

\item{nreps_bs_ci}{The number of iterations used in the bootstrapped confidence interval.}
}
\value{
A list with five components:
\itemize{
  \item{ts}{The test statistic.}
  \item{p_value}{The p value for the test statistic, derived by simulation.}
  \item{count_NA}{The number of \code{NA} values produced in the simulation of the test statistic.
  These generally indicate that the parameter estimation failed.}
  \item{p_value_lower}{If \code{bs_ci} is not \code{NULL}, the lower end
  of the confidence interval around the p value, calculated using
  a non-parametric bootstrap with \code{nreps_bs_ci} repetitions.
  Otherwise \code{NA}.}
  \item{p_value_upper}{If \code{bs_ci} is not \code{NULL}, the upper end
  of the confidence interval around the p value, calculated using
  a non-parametric bootstrap with \code{nreps_bs_ci} repetitions.
  Otherwise \code{NA}.}
}
}
\description{
Many statistical tests have null hypotheses that assume a distribution is fully specified
(with its parameters known in advance). It is common to estimate parameters from data,
and in this case a general method for adapting the statistical test is to use
simulation to derive the distribution of the test statistic, and derive the p-value from this distribution.
}
\details{
TODO explain relationship to gof_test_sim_uniparam
}
\examples{
gof_test_sim(rnorm(100))
estimate_unif <- function(x) list(min = min(x), max = max(x))
gof_test_sim(runif(100), dist = "unif", fn_estimate_params = estimate_unif)
}
